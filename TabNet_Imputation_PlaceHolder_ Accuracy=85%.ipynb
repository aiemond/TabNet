{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd115245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Values (Before Introducing Missing Values):\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.348235   0.349890   0.458102   0.703647   0.824123   0.322928   \n",
      "1   0.498819   0.163697   0.842276   0.537371   0.273011   0.488537   \n",
      "2   0.893514   0.887175   0.188144   0.986549   0.855154   0.825018   \n",
      "3   0.984123   0.161337   0.370182   0.842160   0.227979   0.974128   \n",
      "4   0.035229   0.112280   0.937106   0.048855   0.697233   0.791711   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0   0.470692   0.728581   0.886758   0.755525  ...    0.065345    0.324274   \n",
      "1   0.842686   0.222656   0.693628   0.084708  ...    0.312724    0.791988   \n",
      "2   0.608383   0.644597   0.925009   0.649155  ...    0.605175    0.060008   \n",
      "3   0.517608   0.610857   0.461404   0.655599  ...    0.381657    0.349899   \n",
      "4   0.467091   0.664637   0.513832   0.520772  ...    0.179873    0.845256   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0    0.358264    0.672995    0.314067    0.392103    0.206255    0.681618   \n",
      "1    0.412723    0.535820    0.785271    0.321250    0.503367    0.345543   \n",
      "2    0.046537    0.212358    0.062409    0.608636    0.657420    0.111166   \n",
      "3    0.320559    0.892101    0.128715    0.504133    0.079056    0.142695   \n",
      "4    0.549833    0.078222    0.184183    0.266123    0.901890    0.538759   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    0.977360    0.022432  \n",
      "1    0.249627    0.024062  \n",
      "2    0.301496    0.871519  \n",
      "3    0.279394    0.292266  \n",
      "4    0.796888    0.173843  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "Input Data with Missing Values:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0        NaN   0.349890        NaN   0.703647        NaN   0.322928   \n",
      "1   0.498819   0.163697        NaN        NaN   0.273011   0.488537   \n",
      "2   0.893514   0.887175   0.188144        NaN        NaN   0.825018   \n",
      "3        NaN   0.161337   0.370182   0.842160   0.227979   0.974128   \n",
      "4   0.035229   0.112280   0.937106   0.048855   0.697233   0.791711   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0   0.470692        NaN   0.886758        NaN  ...         NaN    0.324274   \n",
      "1        NaN   0.222656   0.693628   0.084708  ...    0.312724    0.791988   \n",
      "2   0.608383        NaN   0.925009   0.649155  ...         NaN    0.060008   \n",
      "3   0.517608   0.610857   0.461404        NaN  ...         NaN    0.349899   \n",
      "4   0.467091   0.664637   0.513832   0.520772  ...         NaN    0.845256   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0    0.358264    0.672995    0.314067    0.392103         NaN         NaN   \n",
      "1    0.412723    0.535820    0.785271         NaN    0.503367    0.345543   \n",
      "2    0.046537    0.212358         NaN         NaN    0.657420    0.111166   \n",
      "3    0.320559    0.892101    0.128715    0.504133    0.079056    0.142695   \n",
      "4    0.549833         NaN    0.184183    0.266123    0.901890    0.538759   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    0.977360    0.022432  \n",
      "1    0.249627    0.024062  \n",
      "2    0.301496    0.871519  \n",
      "3    0.279394    0.292266  \n",
      "4    0.796888    0.173843  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "After Normalizing Input Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0        NaN  -0.514518        NaN   0.697859        NaN  -0.615406   \n",
      "1   0.023574  -1.152910        NaN        NaN  -0.793480  -0.042084   \n",
      "2   1.397436   1.327641  -1.071008        NaN        NaN   1.122778   \n",
      "3        NaN  -1.161002  -0.446720   1.174769  -0.950431   1.638979   \n",
      "4  -1.590095  -1.329198   1.497513  -1.556641   0.685067   1.007472   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0  -0.091040        NaN   1.362696        NaN  ...         NaN   -0.584269   \n",
      "1        NaN  -0.969118   0.690035  -1.431297  ...   -0.673419    1.034912   \n",
      "2   0.385488        NaN   1.495923   0.512793  ...         NaN   -1.499134   \n",
      "3   0.071331   0.365679  -0.118785        NaN  ...         NaN   -0.495557   \n",
      "4  -0.103503   0.550595   0.063818   0.070613  ...         NaN    1.219323   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0   -0.474256    0.575421   -0.642782   -0.365769         NaN         NaN   \n",
      "1   -0.287034    0.099756    0.991457         NaN    0.000581   -0.548041   \n",
      "2   -1.545925   -1.021877         NaN         NaN    0.537058   -1.373867   \n",
      "3   -0.603879    1.335190   -1.285626    0.017473   -1.477048   -1.262775   \n",
      "4    0.184329         NaN   -1.093249   -0.796732    1.388403    0.132756   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    1.648396   -1.615618  \n",
      "1   -0.860635   -1.610062  \n",
      "2   -0.681806    1.278001  \n",
      "3   -0.758006   -0.696045  \n",
      "4    1.026174   -1.099620  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "Filled Missing Values with Zero Placeholder:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.000000  -0.514518   0.000000   0.697859   0.000000  -0.615406   \n",
      "1   0.023574  -1.152910   0.000000   0.000000  -0.793480  -0.042084   \n",
      "2   1.397436   1.327641  -1.071008   0.000000   0.000000   1.122778   \n",
      "3   0.000000  -1.161002  -0.446720   1.174769  -0.950431   1.638979   \n",
      "4  -1.590095  -1.329198   1.497513  -1.556641   0.685067   1.007472   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0  -0.091040   0.000000   1.362696   0.000000  ...    0.000000   -0.584269   \n",
      "1   0.000000  -0.969118   0.690035  -1.431297  ...   -0.673419    1.034912   \n",
      "2   0.385488   0.000000   1.495923   0.512793  ...    0.000000   -1.499134   \n",
      "3   0.071331   0.365679  -0.118785   0.000000  ...    0.000000   -0.495557   \n",
      "4  -0.103503   0.550595   0.063818   0.070613  ...    0.000000    1.219323   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0   -0.474256    0.575421   -0.642782   -0.365769    0.000000    0.000000   \n",
      "1   -0.287034    0.099756    0.991457    0.000000    0.000581   -0.548041   \n",
      "2   -1.545925   -1.021877    0.000000    0.000000    0.537058   -1.373867   \n",
      "3   -0.603879    1.335190   -1.285626    0.017473   -1.477048   -1.262775   \n",
      "4    0.184329    0.000000   -1.093249   -0.796732    1.388403    0.132756   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    1.648396   -1.615618  \n",
      "1   -0.860635   -1.610062  \n",
      "2   -0.681806    1.278001  \n",
      "3   -0.758006   -0.696045  \n",
      "4    1.026174   -1.099620  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 3.19076 |  0:00:08s\n",
      "epoch 1  | loss: 1.41169 |  0:00:19s\n",
      "epoch 2  | loss: 1.10132 |  0:00:28s\n",
      "epoch 3  | loss: 1.03671 |  0:00:39s\n",
      "epoch 4  | loss: 1.01604 |  0:00:50s\n",
      "epoch 5  | loss: 1.00703 |  0:00:59s\n",
      "epoch 6  | loss: 1.00642 |  0:01:09s\n",
      "epoch 7  | loss: 1.00416 |  0:01:30s\n",
      "epoch 8  | loss: 0.99542 |  0:01:43s\n",
      "epoch 9  | loss: 0.9995  |  0:01:47s\n",
      "epoch 10 | loss: 0.99844 |  0:02:07s\n",
      "epoch 11 | loss: 1.00498 |  0:02:15s\n",
      "epoch 12 | loss: 0.99711 |  0:02:24s\n",
      "epoch 13 | loss: 1.00021 |  0:02:30s\n",
      "epoch 14 | loss: 1.00111 |  0:02:43s\n",
      "epoch 15 | loss: 0.99717 |  0:02:52s\n",
      "epoch 16 | loss: 0.9975  |  0:03:01s\n",
      "epoch 17 | loss: 1.00097 |  0:03:12s\n",
      "epoch 18 | loss: 0.99867 |  0:03:23s\n",
      "epoch 19 | loss: 1.00273 |  0:03:33s\n",
      "epoch 20 | loss: 1.00279 |  0:03:43s\n",
      "epoch 21 | loss: 0.99604 |  0:03:52s\n",
      "epoch 22 | loss: 0.99922 |  0:04:01s\n",
      "epoch 23 | loss: 1.00103 |  0:04:10s\n",
      "epoch 24 | loss: 1.0042  |  0:04:19s\n",
      "epoch 25 | loss: 0.99695 |  0:04:28s\n",
      "epoch 26 | loss: 1.00327 |  0:04:38s\n",
      "epoch 27 | loss: 1.0002  |  0:04:49s\n",
      "epoch 28 | loss: 0.99794 |  0:05:00s\n",
      "epoch 29 | loss: 0.99907 |  0:05:09s\n",
      "epoch 30 | loss: 1.00456 |  0:05:20s\n",
      "epoch 31 | loss: 0.99577 |  0:05:29s\n",
      "epoch 32 | loss: 1.00301 |  0:05:37s\n",
      "epoch 33 | loss: 1.00039 |  0:05:47s\n",
      "epoch 34 | loss: 1.00189 |  0:05:56s\n",
      "epoch 35 | loss: 1.00113 |  0:06:04s\n",
      "epoch 36 | loss: 1.00276 |  0:06:14s\n",
      "epoch 37 | loss: 1.00444 |  0:06:22s\n",
      "epoch 38 | loss: 1.00056 |  0:06:31s\n",
      "epoch 39 | loss: 1.0025  |  0:06:40s\n",
      "epoch 40 | loss: 0.99925 |  0:06:51s\n",
      "epoch 41 | loss: 0.99987 |  0:07:00s\n",
      "epoch 42 | loss: 1.00129 |  0:07:08s\n",
      "epoch 43 | loss: 0.99986 |  0:07:18s\n",
      "epoch 44 | loss: 0.9966  |  0:07:26s\n",
      "epoch 45 | loss: 1.001   |  0:07:35s\n",
      "epoch 46 | loss: 1.00134 |  0:07:44s\n",
      "epoch 47 | loss: 1.00214 |  0:07:53s\n",
      "epoch 48 | loss: 1.00208 |  0:08:01s\n",
      "epoch 49 | loss: 0.99878 |  0:08:09s\n",
      "\n",
      "Pretrained TabNet Model:\n",
      "\n",
      "True missing values:\n",
      "[[ 0.         -0.51451767  0.         ...  0.          1.64839563\n",
      "  -1.61561815]\n",
      " [ 0.02357444 -1.15291026  0.         ... -0.54804116 -0.86063451\n",
      "  -1.61006204]\n",
      " [ 1.39743584  1.32764123 -1.07100773 ... -1.37386741 -0.68180617\n",
      "   1.27800056]\n",
      " ...\n",
      " [ 0.         -0.05662681  0.7428034  ...  0.          0.\n",
      "   0.34110133]\n",
      " [-0.09693367  0.12409952 -1.45577039 ...  0.         -1.39434418\n",
      "   0.        ]\n",
      " [ 0.28062886 -0.40824226  1.40602825 ... -0.6775838   0.\n",
      "  -0.25792176]]\n",
      "\n",
      "Reconstructed data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.000000  -0.514518   0.000000   0.697859   0.000000  -0.615406   \n",
      "1   0.023574  -1.152910   0.000000   0.000000  -0.793480  -0.042084   \n",
      "2   1.397436   1.327641  -1.071008   0.000000   0.000000   1.122778   \n",
      "3   0.000000  -1.161002  -0.446720   1.174769  -0.950431   1.638979   \n",
      "4  -1.590095  -1.329198   1.497513  -1.556641   0.685067   1.007472   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0  -0.091040   0.000000   1.362696   0.000000  ...    0.000000   -0.584269   \n",
      "1   0.000000  -0.969118   0.690035  -1.431297  ...   -0.673419    1.034912   \n",
      "2   0.385488   0.000000   1.495923   0.512793  ...    0.000000   -1.499134   \n",
      "3   0.071331   0.365679  -0.118785   0.000000  ...    0.000000   -0.495557   \n",
      "4  -0.103503   0.550595   0.063818   0.070613  ...    0.000000    1.219323   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0   -0.474256    0.575421   -0.642782   -0.365769    0.000000    0.000000   \n",
      "1   -0.287034    0.099756    0.991457    0.000000    0.000581   -0.548041   \n",
      "2   -1.545925   -1.021877    0.000000    0.000000    0.537058   -1.373867   \n",
      "3   -0.603879    1.335190   -1.285626    0.017473   -1.477048   -1.262775   \n",
      "4    0.184329    0.000000   -1.093249   -0.796732    1.388403    0.132756   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    1.648396   -1.615618  \n",
      "1   -0.860635   -1.610062  \n",
      "2   -0.681806    1.278001  \n",
      "3   -0.758006   -0.696045  \n",
      "4    1.026174   -1.099620  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "Imputed values:\n",
      "[[ 0.         -0.51451767  0.         ...  0.          1.64839563\n",
      "  -1.61561815]\n",
      " [ 0.02357444 -1.15291026  0.         ... -0.54804116 -0.86063451\n",
      "  -1.61006204]\n",
      " [ 1.39743584  1.32764123 -1.07100773 ... -1.37386741 -0.68180617\n",
      "   1.27800056]\n",
      " ...\n",
      " [ 0.         -0.05662681  0.7428034  ...  0.          0.\n",
      "   0.34110133]\n",
      " [-0.09693367  0.12409952 -1.45577039 ...  0.         -1.39434418\n",
      "   0.        ]\n",
      " [ 0.28062886 -0.40824226  1.40602825 ... -0.6775838   0.\n",
      "  -0.25792176]]\n",
      "\n",
      "Denormalized Reconstructed Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.492046   0.349890   0.500442   0.703647   0.500675   0.322928   \n",
      "1   0.498819   0.163697   0.500442   0.500963   0.273011   0.488537   \n",
      "2   0.893514   0.887175   0.188144   0.500963   0.500675   0.825018   \n",
      "3   0.492046   0.161337   0.370182   0.842160   0.227979   0.974128   \n",
      "4   0.035229   0.112280   0.937106   0.048855   0.697233   0.791711   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0   0.470692   0.504506   0.886758   0.500271  ...    0.506298    0.324274   \n",
      "1   0.496998   0.222656   0.693628   0.084708  ...    0.312724    0.791988   \n",
      "2   0.608383   0.504506   0.925009   0.649155  ...    0.506298    0.060008   \n",
      "3   0.517608   0.610857   0.461404   0.500271  ...    0.506298    0.349899   \n",
      "4   0.467091   0.664637   0.513832   0.520772  ...    0.506298    0.845256   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0    0.358264    0.672995    0.314067    0.392103    0.503200    0.501082   \n",
      "1    0.412723    0.535820    0.785271    0.499025    0.503367    0.345543   \n",
      "2    0.046537    0.212358    0.499402    0.499025    0.657420    0.111166   \n",
      "3    0.320559    0.892101    0.128715    0.504133    0.079056    0.142695   \n",
      "4    0.549833    0.507052    0.184183    0.266123    0.901890    0.538759   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    0.977360    0.022432  \n",
      "1    0.249627    0.024062  \n",
      "2    0.301496    0.871519  \n",
      "3    0.279394    0.292266  \n",
      "4    0.796888    0.173843  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "Ground Values (Before Processing, At the End):\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.348235   0.349890   0.458102   0.703647   0.824123   0.322928   \n",
      "1   0.498819   0.163697   0.842276   0.537371   0.273011   0.488537   \n",
      "2   0.893514   0.887175   0.188144   0.986549   0.855154   0.825018   \n",
      "3   0.984123   0.161337   0.370182   0.842160   0.227979   0.974128   \n",
      "4   0.035229   0.112280   0.937106   0.048855   0.697233   0.791711   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_50  feature_51  \\\n",
      "0   0.470692   0.728581   0.886758   0.755525  ...    0.065345    0.324274   \n",
      "1   0.842686   0.222656   0.693628   0.084708  ...    0.312724    0.791988   \n",
      "2   0.608383   0.644597   0.925009   0.649155  ...    0.605175    0.060008   \n",
      "3   0.517608   0.610857   0.461404   0.655599  ...    0.381657    0.349899   \n",
      "4   0.467091   0.664637   0.513832   0.520772  ...    0.179873    0.845256   \n",
      "\n",
      "   feature_52  feature_53  feature_54  feature_55  feature_56  feature_57  \\\n",
      "0    0.358264    0.672995    0.314067    0.392103    0.206255    0.681618   \n",
      "1    0.412723    0.535820    0.785271    0.321250    0.503367    0.345543   \n",
      "2    0.046537    0.212358    0.062409    0.608636    0.657420    0.111166   \n",
      "3    0.320559    0.892101    0.128715    0.504133    0.079056    0.142695   \n",
      "4    0.549833    0.078222    0.184183    0.266123    0.901890    0.538759   \n",
      "\n",
      "   feature_58  feature_59  \n",
      "0    0.977360    0.022432  \n",
      "1    0.249627    0.024062  \n",
      "2    0.301496    0.871519  \n",
      "3    0.279394    0.292266  \n",
      "4    0.796888    0.173843  \n",
      "\n",
      "[5 rows x 60 columns]\n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.1584078307739612\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Generate random data\n",
    "n_samples = 5000  # Adjust the number of samples as needed\n",
    "n_features = 60   # Adjust the number of features as needed\n",
    "data = np.random.rand(n_samples, n_features)\n",
    "df = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "\n",
    "# Print the ground values before introducing missing values\n",
    "print(\"Ground Values (Before Introducing Missing Values):\")\n",
    "print(df.head())\n",
    "\n",
    "# Store a copy of the ground values\n",
    "ground_values = df.copy()\n",
    "\n",
    "# Introduce random missing values\n",
    "missing_fraction = 0.3  # Adjust the fraction of missing values as needed\n",
    "mask = np.random.rand(n_samples, n_features) < missing_fraction\n",
    "df[mask] = np.nan\n",
    "\n",
    "# Print the input dataset with missing values\n",
    "print(\"\\nInput Data with Missing Values:\")\n",
    "print(df.head())\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Store the normalized data in a separate variable\n",
    "df_normalized = df.copy()\n",
    "\n",
    "print('After Normalizing Input Data:')\n",
    "print(df.head())\n",
    "\n",
    "df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "print(\"\\nFilled Missing Values with Zero Placeholder:\")\n",
    "print(df.head()) \n",
    "\n",
    "# Pretrain the TabNet model\n",
    "pretrained_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax',\n",
    "    n_d=32,  # Increase the number of decision steps\n",
    "    n_a=32   # Increase the number of features shared\n",
    ")\n",
    "\n",
    "max_epochs = 50\n",
    "pretrained_model.fit(\n",
    "    df[numeric_cols].values,\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "print(\"\\nPretrained TabNet Model:\")\n",
    "\n",
    "# Define the tabnet_recon function\n",
    "def tabnet_recon(df, network, df_mean=0, df_std=1):\n",
    "    df_train = df.copy()\n",
    "    df_train[numeric_cols] = scaler.transform(df_train[numeric_cols])\n",
    "    \n",
    "    # Convert input data to tensors for use in the TabNet network\n",
    "    input_data = torch.tensor(df_train[numeric_cols].values, dtype=torch.float32)\n",
    "    \n",
    "    # Pass the input data through the TabNet network\n",
    "    results = network.predict(input_data)\n",
    "    \n",
    "    # Handle potential tuple output\n",
    "    if isinstance(results, tuple):\n",
    "        results = results[0]  # Use the first element of the tuple\n",
    "    \n",
    "    # Denormalize the reconstructed data\n",
    "    df_na_tab = (results * df_std) + df_mean\n",
    "    \n",
    "    # Patch the reconstructed data into the original data with missing values\n",
    "    df_rec_tab = df.copy()\n",
    "    df_rec_tab.update(df_na_tab)\n",
    "    \n",
    "    return df_rec_tab\n",
    "\n",
    "# Extract true missing values before filling\n",
    "true_missing_values = df[numeric_cols].values  # Replace df_original with df\n",
    "\n",
    "\n",
    "print('\\nTrue missing values:')\n",
    "print(true_missing_values)\n",
    "\n",
    "# Reconstruct missing values using the pretrained model\n",
    "reconstructed_data = tabnet_recon(df, network=pretrained_model)\n",
    "\n",
    "print('\\nReconstructed data:')\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Extract imputed values\n",
    "imputed_values = reconstructed_data[numeric_cols].values\n",
    "\n",
    "print('\\nImputed values:')\n",
    "print(imputed_values)\n",
    "\n",
    "# Denormalize the reconstructed data\n",
    "reconstructed_data[numeric_cols] = scaler.inverse_transform(reconstructed_data[numeric_cols])\n",
    "\n",
    "# Compare the denormalized reconstructed data with the original input data\n",
    "\n",
    "print(\"\\nDenormalized Reconstructed Data:\")\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Print the ground values again (before processing) at the end\n",
    "print(\"\\nGround Values (Before Processing, At the End):\")\n",
    "print(ground_values.head())\n",
    "\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = math.sqrt(mean_squared_error(ground_values[numeric_cols].values, reconstructed_data[numeric_cols].values))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4f2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
