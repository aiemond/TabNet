{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee358d5",
   "metadata": {},
   "source": [
    "# Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dc3d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0        5.1        3.5        1.4        0.2\n",
      "1        4.9        3.0        1.4        0.2\n",
      "2        4.7        3.2        1.3        0.2\n",
      "3        4.6        3.1        1.5        0.2\n",
      "4        5.0        3.6        1.4        0.2\n",
      "\n",
      "Input Data with Missing Values:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0        5.1        3.5        1.4        0.2\n",
      "1        4.9        3.0        NaN        NaN\n",
      "2        NaN        NaN        1.3        0.2\n",
      "3        NaN        3.1        1.5        0.2\n",
      "4        5.0        3.6        1.4        0.2\n",
      "\n",
      "After Normalizing Input Data:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0  -0.904167   0.994617  -1.326042  -1.253879\n",
      "1  -1.140036  -0.197561        NaN        NaN\n",
      "2        NaN        NaN  -1.382446  -1.253879\n",
      "3        NaN   0.040875  -1.269638  -1.253879\n",
      "4  -1.022101   1.233053  -1.326042  -1.253879\n",
      "\n",
      "Filled Missing Values with Zero Placeholder:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0  -0.904167   0.994617  -1.326042  -1.253879\n",
      "1  -1.140036  -0.197561   0.000000   0.000000\n",
      "2   0.000000   0.000000  -1.382446  -1.253879\n",
      "3   0.000000   0.040875  -1.269638  -1.253879\n",
      "4  -1.022101   1.233053  -1.326042  -1.253879\n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 3.09603 |  0:00:00s\n",
      "epoch 1  | loss: 3.55214 |  0:00:00s\n",
      "epoch 2  | loss: 1.63642 |  0:00:01s\n",
      "epoch 3  | loss: 3.40509 |  0:00:01s\n",
      "epoch 4  | loss: 1.5134  |  0:00:01s\n",
      "epoch 5  | loss: 1.57888 |  0:00:02s\n",
      "epoch 6  | loss: 0.93042 |  0:00:02s\n",
      "epoch 7  | loss: 1.62103 |  0:00:02s\n",
      "epoch 8  | loss: 1.85085 |  0:00:03s\n",
      "epoch 9  | loss: 1.24739 |  0:00:03s\n",
      "epoch 10 | loss: 0.92125 |  0:00:04s\n",
      "epoch 11 | loss: 0.81576 |  0:00:04s\n",
      "epoch 12 | loss: 1.27768 |  0:00:05s\n",
      "epoch 13 | loss: 0.74735 |  0:00:06s\n",
      "epoch 14 | loss: 0.87048 |  0:00:06s\n",
      "epoch 15 | loss: 0.70313 |  0:00:06s\n",
      "epoch 16 | loss: 0.88232 |  0:00:06s\n",
      "epoch 17 | loss: 0.61641 |  0:00:06s\n",
      "epoch 18 | loss: 0.69625 |  0:00:07s\n",
      "epoch 19 | loss: 0.90537 |  0:00:07s\n",
      "epoch 20 | loss: 0.79436 |  0:00:07s\n",
      "epoch 21 | loss: 0.76092 |  0:00:07s\n",
      "epoch 22 | loss: 0.80421 |  0:00:08s\n",
      "epoch 23 | loss: 0.67979 |  0:00:08s\n",
      "epoch 24 | loss: 0.6783  |  0:00:08s\n",
      "epoch 25 | loss: 0.73165 |  0:00:08s\n",
      "epoch 26 | loss: 0.62661 |  0:00:09s\n",
      "epoch 27 | loss: 0.65869 |  0:00:09s\n",
      "epoch 28 | loss: 0.74062 |  0:00:09s\n",
      "epoch 29 | loss: 0.71433 |  0:00:09s\n",
      "epoch 30 | loss: 0.68862 |  0:00:09s\n",
      "epoch 31 | loss: 0.65381 |  0:00:10s\n",
      "epoch 32 | loss: 0.6612  |  0:00:10s\n",
      "epoch 33 | loss: 0.60757 |  0:00:10s\n",
      "epoch 34 | loss: 0.70586 |  0:00:10s\n",
      "epoch 35 | loss: 0.72341 |  0:00:11s\n",
      "epoch 36 | loss: 0.62694 |  0:00:11s\n",
      "epoch 37 | loss: 0.8518  |  0:00:11s\n",
      "epoch 38 | loss: 0.70666 |  0:00:12s\n",
      "epoch 39 | loss: 0.68209 |  0:00:12s\n",
      "epoch 40 | loss: 0.69544 |  0:00:12s\n",
      "epoch 41 | loss: 0.84845 |  0:00:13s\n",
      "epoch 42 | loss: 0.63329 |  0:00:13s\n",
      "epoch 43 | loss: 0.67226 |  0:00:13s\n",
      "epoch 44 | loss: 0.6131  |  0:00:14s\n",
      "epoch 45 | loss: 0.60354 |  0:00:14s\n",
      "epoch 46 | loss: 0.63307 |  0:00:15s\n",
      "epoch 47 | loss: 0.63671 |  0:00:15s\n",
      "epoch 48 | loss: 0.63904 |  0:00:15s\n",
      "epoch 49 | loss: 0.78833 |  0:00:16s\n",
      "epoch 50 | loss: 0.69754 |  0:00:16s\n",
      "epoch 51 | loss: 0.61503 |  0:00:16s\n",
      "epoch 52 | loss: 0.64714 |  0:00:16s\n",
      "epoch 53 | loss: 0.56807 |  0:00:17s\n",
      "epoch 54 | loss: 0.62304 |  0:00:18s\n",
      "epoch 55 | loss: 0.66383 |  0:00:18s\n",
      "epoch 56 | loss: 0.6563  |  0:00:18s\n",
      "epoch 57 | loss: 0.54314 |  0:00:19s\n",
      "epoch 58 | loss: 0.50996 |  0:00:19s\n",
      "epoch 59 | loss: 0.66079 |  0:00:20s\n",
      "epoch 60 | loss: 0.62835 |  0:00:20s\n",
      "epoch 61 | loss: 0.61885 |  0:00:21s\n",
      "epoch 62 | loss: 0.61549 |  0:00:21s\n",
      "epoch 63 | loss: 0.53486 |  0:00:22s\n",
      "epoch 64 | loss: 0.61626 |  0:00:22s\n",
      "epoch 65 | loss: 0.62341 |  0:00:23s\n",
      "epoch 66 | loss: 0.66936 |  0:00:23s\n",
      "epoch 67 | loss: 0.57252 |  0:00:24s\n",
      "epoch 68 | loss: 0.66025 |  0:00:24s\n",
      "epoch 69 | loss: 0.7694  |  0:00:25s\n",
      "epoch 70 | loss: 0.63911 |  0:00:25s\n",
      "epoch 71 | loss: 0.58588 |  0:00:26s\n",
      "epoch 72 | loss: 0.57626 |  0:00:27s\n",
      "epoch 73 | loss: 0.55456 |  0:00:27s\n",
      "epoch 74 | loss: 0.67062 |  0:00:27s\n",
      "epoch 75 | loss: 0.61286 |  0:00:27s\n",
      "epoch 76 | loss: 0.64115 |  0:00:27s\n",
      "epoch 77 | loss: 0.58741 |  0:00:27s\n",
      "epoch 78 | loss: 0.57946 |  0:00:28s\n",
      "epoch 79 | loss: 0.57261 |  0:00:28s\n",
      "epoch 80 | loss: 0.71644 |  0:00:28s\n",
      "epoch 81 | loss: 0.5494  |  0:00:29s\n",
      "epoch 82 | loss: 0.59922 |  0:00:29s\n",
      "epoch 83 | loss: 0.5792  |  0:00:29s\n",
      "epoch 84 | loss: 0.68417 |  0:00:29s\n",
      "epoch 85 | loss: 0.63016 |  0:00:29s\n",
      "epoch 86 | loss: 0.56402 |  0:00:30s\n",
      "epoch 87 | loss: 0.55327 |  0:00:30s\n",
      "epoch 88 | loss: 0.56226 |  0:00:30s\n",
      "epoch 89 | loss: 0.60169 |  0:00:30s\n",
      "epoch 90 | loss: 0.63685 |  0:00:30s\n",
      "epoch 91 | loss: 0.55539 |  0:00:31s\n",
      "epoch 92 | loss: 0.64448 |  0:00:31s\n",
      "epoch 93 | loss: 0.5866  |  0:00:32s\n",
      "epoch 94 | loss: 0.65721 |  0:00:32s\n",
      "epoch 95 | loss: 0.66461 |  0:00:32s\n",
      "epoch 96 | loss: 0.59959 |  0:00:32s\n",
      "epoch 97 | loss: 0.54682 |  0:00:33s\n",
      "epoch 98 | loss: 0.52772 |  0:00:33s\n",
      "epoch 99 | loss: 0.52999 |  0:00:34s\n",
      "\n",
      "Pretrained TabNet Model:\n",
      "\n",
      "True Missing Values:\n",
      "[[-0.90416665  0.99461749 -1.32604188 -1.25387926]\n",
      " [-1.14003621 -0.19756101  0.          0.        ]\n",
      " [ 0.          0.         -1.38244566 -1.25387926]\n",
      " [ 0.          0.04087469 -1.2696381  -1.25387926]\n",
      " [-1.02210143  1.23305319 -1.32604188 -1.25387926]\n",
      " [-0.55036231  1.94836028 -1.15683053 -0.99054046]\n",
      " [-1.49384055  0.         -1.32604188 -1.12220986]\n",
      " [ 0.          0.         -1.2696381   0.        ]\n",
      " [-1.72971012 -0.43599671 -1.32604188 -1.25387926]\n",
      " [-1.14003621  0.04087469 -1.2696381  -1.38554867]\n",
      " [-0.55036231  1.47148889  0.         -1.25387926]\n",
      " [-1.25797099  0.75618179 -1.21323431 -1.25387926]\n",
      " [-1.25797099 -0.19756101  0.          0.        ]\n",
      " [-1.8476449  -0.19756101 -1.49525323 -1.38554867]\n",
      " [-0.07862319  0.          0.         -1.25387926]\n",
      " [-0.19655797  3.14053878  0.         -0.99054046]\n",
      " [ 0.          1.94836028 -1.38244566  0.        ]\n",
      " [ 0.          0.99461749  0.         -1.12220986]\n",
      " [-0.19655797  1.70992458 -1.15683053 -1.12220986]\n",
      " [-0.90416665  0.         -1.2696381  -1.12220986]\n",
      " [-0.55036231  0.         -1.15683053 -1.25387926]\n",
      " [-0.90416665  1.47148889  0.         -0.99054046]\n",
      " [-1.49384055  1.23305319 -1.55165701 -1.25387926]\n",
      " [ 0.          0.51774609  0.         -0.85887106]\n",
      " [ 0.          0.75618179  0.         -1.25387926]\n",
      " [-1.02210143 -0.19756101  0.         -1.25387926]\n",
      " [-1.02210143  0.75618179 -1.21323431 -0.99054046]\n",
      " [ 0.          0.          0.         -1.25387926]\n",
      " [-0.78623187  0.75618179 -1.32604188 -1.25387926]\n",
      " [-1.37590577  0.         -1.21323431 -1.25387926]\n",
      " [-1.25797099  0.04087469  0.         -1.25387926]\n",
      " [ 0.          0.75618179 -1.2696381  -0.99054046]\n",
      " [-0.78623187  0.         -1.2696381   0.        ]\n",
      " [-0.43242753  2.66366738 -1.32604188 -1.25387926]\n",
      " [ 0.          0.04087469  0.         -1.25387926]\n",
      " [-1.02210143  0.27931039 -1.43884945 -1.25387926]\n",
      " [-0.43242753  0.99461749 -1.38244566 -1.25387926]\n",
      " [-1.14003621  1.23305319 -1.32604188 -1.38554867]\n",
      " [-1.72971012 -0.19756101 -1.38244566 -1.25387926]\n",
      " [ 0.          0.75618179  0.          0.        ]\n",
      " [-1.02210143  0.99461749 -1.38244566 -1.12220986]\n",
      " [-1.61177534 -1.8666109  -1.38244566  0.        ]\n",
      " [-1.72971012  0.27931039  0.          0.        ]\n",
      " [-1.02210143  0.99461749  0.          0.        ]\n",
      " [-0.90416665  1.70992458 -1.04402297 -0.99054046]\n",
      " [ 0.         -0.19756101 -1.32604188  0.        ]\n",
      " [-0.90416665  0.         -1.21323431 -1.25387926]\n",
      " [-1.49384055  0.27931039 -1.32604188  0.        ]\n",
      " [ 0.          1.47148889 -1.2696381  -1.25387926]\n",
      " [-1.02210143  0.51774609 -1.32604188 -1.25387926]\n",
      " [ 1.33659418  0.27931039  0.53528296  0.        ]\n",
      " [ 0.6289855   0.          0.42247539  0.45782297]\n",
      " [ 0.          0.04087469  0.          0.45782297]\n",
      " [ 0.          0.          0.14045648  0.        ]\n",
      " [ 0.74692028  0.          0.          0.45782297]\n",
      " [-0.19655797 -0.67443241  0.          0.19448416]\n",
      " [ 0.51105072  0.51774609  0.          0.58949237]\n",
      " [-1.14003621  0.         -0.25437    -0.20052404]\n",
      " [ 0.86485506 -0.43599671  0.47887918  0.19448416]\n",
      " [-0.78623187 -0.9128681   0.0840527   0.32615357]\n",
      " [-1.02210143  0.         -0.14156244 -0.20052404]\n",
      " [ 0.03931159 -0.19756101  0.          0.        ]\n",
      " [ 0.15724637  0.          0.14045648 -0.20052404]\n",
      " [ 0.27518115 -0.43599671  0.53528296  0.32615357]\n",
      " [-0.31449275 -0.43599671 -0.08515865  0.19448416]\n",
      " [ 0.98278984  0.04087469  0.          0.32615357]\n",
      " [ 0.         -0.19756101  0.42247539  0.45782297]\n",
      " [-0.07862319  0.          0.19686026 -0.20052404]\n",
      " [ 0.         -2.1050466   0.42247539  0.        ]\n",
      " [ 0.          0.          0.0840527   0.        ]\n",
      " [ 0.03931159  0.          0.          0.85283118]\n",
      " [ 0.27518115 -0.67443241  0.          0.19448416]\n",
      " [ 0.51105072 -1.3897395   0.          0.45782297]\n",
      " [ 0.27518115  0.          0.53528296  0.06281476]\n",
      " [ 0.         -0.43599671  0.30966783  0.19448416]\n",
      " [ 0.86485506  0.          0.          0.32615357]\n",
      " [ 1.10072462  0.          0.59168674  0.32615357]\n",
      " [ 0.          0.          0.70449431  0.72116177]\n",
      " [ 0.15724637  0.          0.          0.45782297]\n",
      " [-0.19655797 -1.1513038  -0.14156244 -0.20052404]\n",
      " [ 0.         -1.6281752   0.          0.        ]\n",
      " [ 0.         -1.6281752   0.          0.        ]\n",
      " [-0.07862319 -0.9128681   0.0840527   0.06281476]\n",
      " [ 0.         -0.9128681   0.76089809  0.58949237]\n",
      " [-0.55036231 -0.19756101  0.          0.        ]\n",
      " [ 0.15724637  0.75618179  0.42247539  0.58949237]\n",
      " [ 0.98278984  0.          0.          0.        ]\n",
      " [ 0.51105072 -1.8666109   0.36607161  0.19448416]\n",
      " [-0.31449275 -0.19756101  0.19686026  0.        ]\n",
      " [ 0.          0.          0.14045648  0.19448416]\n",
      " [-0.43242753 -1.1513038   0.36607161  0.06281476]\n",
      " [ 0.27518115  0.          0.47887918  0.32615357]\n",
      " [-0.07862319 -1.1513038   0.          0.06281476]\n",
      " [-1.02210143 -1.8666109   0.          0.        ]\n",
      " [-0.31449275  0.          0.25326405  0.        ]\n",
      " [-0.19655797 -0.19756101  0.          0.06281476]\n",
      " [ 0.          0.          0.25326405  0.19448416]\n",
      " [ 0.39311594 -0.43599671  0.30966783  0.19448416]\n",
      " [ 0.         -1.3897395  -0.42358135 -0.06885464]\n",
      " [-0.19655797  0.          0.19686026  0.19448416]\n",
      " [ 0.51105072  0.51774609  1.26853214  1.77451699]\n",
      " [ 0.         -0.9128681   0.76089809  0.        ]\n",
      " [ 1.45452896 -0.19756101  0.          1.24783938]\n",
      " [ 0.51105072 -0.43599671  1.04291701  0.85283118]\n",
      " [ 0.74692028 -0.19756101  1.15572458  1.37950879]\n",
      " [ 2.04420286 -0.19756101  1.60695484  1.24783938]\n",
      " [-1.14003621 -1.3897395   0.42247539  0.72116177]\n",
      " [ 1.69039852 -0.43599671  0.          0.85283118]\n",
      " [ 0.98278984 -1.3897395   0.          0.85283118]\n",
      " [ 1.57246374  1.23305319  1.32493592  1.77451699]\n",
      " [ 0.          0.          0.76089809  1.11616998]\n",
      " [ 0.         -0.9128681   0.87370566  0.98450058]\n",
      " [ 0.         -0.19756101  0.98651323  0.        ]\n",
      " [-0.19655797  0.          0.          1.11616998]\n",
      " [ 0.          0.          0.          1.64284759]\n",
      " [ 0.6289855   0.          0.87370566  0.        ]\n",
      " [ 0.74692028 -0.19756101  0.98651323  0.85283118]\n",
      " [ 2.16213764  1.70992458  0.          1.37950879]\n",
      " [ 0.         -1.1513038   1.77616619  1.51117819]\n",
      " [ 0.15724637  0.          0.          0.45782297]\n",
      " [ 0.          0.          1.09932079  1.51117819]\n",
      " [ 0.          0.          0.64809053  1.11616998]\n",
      " [ 2.16213764 -0.67443241  1.66335862  0.        ]\n",
      " [ 0.         -0.9128681   0.64809053  0.85283118]\n",
      " [ 0.98278984  0.51774609  1.09932079  1.24783938]\n",
      " [ 1.57246374  0.27931039  0.          0.        ]\n",
      " [ 0.39311594  0.          0.59168674  0.        ]\n",
      " [ 0.27518115 -0.19756101  0.64809053  0.85283118]\n",
      " [ 0.6289855   0.          0.          0.        ]\n",
      " [ 1.57246374 -0.19756101  1.15572458  0.        ]\n",
      " [ 0.         -0.67443241  1.32493592  0.98450058]\n",
      " [ 2.39800721  0.          1.49414727  0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.51105072 -0.67443241  0.76089809  0.45782297]\n",
      " [ 0.27518115 -1.1513038   1.04291701  0.        ]\n",
      " [ 2.16213764  0.          1.32493592  1.51117819]\n",
      " [ 0.51105072  0.75618179  1.04291701  1.64284759]\n",
      " [ 0.6289855   0.          0.98651323  0.85283118]\n",
      " [ 0.15724637 -0.19756101  0.59168674  0.        ]\n",
      " [ 1.2186594   0.04087469  0.93010944  0.        ]\n",
      " [ 0.98278984  0.04087469  1.04291701  0.        ]\n",
      " [ 1.2186594   0.          0.          0.        ]\n",
      " [ 0.         -0.9128681   0.76089809  0.98450058]\n",
      " [ 1.10072462  0.27931039  0.          1.51117819]\n",
      " [ 0.98278984  0.51774609  0.          0.        ]\n",
      " [ 0.98278984  0.          0.          1.51117819]\n",
      " [ 0.         -1.3897395   0.70449431  0.        ]\n",
      " [ 0.74692028 -0.19756101  0.81730188  1.11616998]\n",
      " [ 0.39311594  0.75618179  0.93010944  1.51117819]\n",
      " [ 0.03931159 -0.19756101  0.76089809  0.        ]]\n",
      "\n",
      "Reconstructed Data:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0  -1.774432  -0.696038  -3.027794  -1.496668\n",
      "1  -2.274907  -0.962799   0.224306  -1.161062\n",
      "2  -1.777746  -0.693319  -3.031115  -1.482611\n",
      "3  -1.767799  -0.695355  -3.021371  -1.511127\n",
      "4  -1.774647  -0.696255  -3.027995  -1.496647\n",
      "\n",
      "Imputed Values:\n",
      "[[-1.77443218e+00 -6.96037531e-01 -3.02779365e+00 -1.49666786e+00]\n",
      " [-2.27490687e+00 -9.62799191e-01  2.24306077e-01 -1.16106224e+00]\n",
      " [-1.77774644e+00 -6.93319380e-01 -3.03111506e+00 -1.48261058e+00]\n",
      " [-1.76779866e+00 -6.95355117e-01 -3.02137089e+00 -1.51112664e+00]\n",
      " [-1.77464700e+00 -6.96254790e-01 -3.02799511e+00 -1.49664652e+00]\n",
      " [-1.72655392e+00 -6.11308992e-01 -2.91494179e+00 -1.22263741e+00]\n",
      " [-1.73453391e+00 -6.35228932e-01 -2.96129322e+00 -1.33272231e+00]\n",
      " [-3.21563482e+00 -1.77117968e+00 -7.50635505e-01 -1.45267391e+00]\n",
      " [-1.77593863e+00 -6.97562158e-01 -3.02919936e+00 -1.49651265e+00]\n",
      " [-1.87506592e+00 -8.27785969e-01 -3.15586972e+00 -1.68132591e+00]\n",
      " [-1.64721572e+00 -6.94768488e-01 -2.90816450e+00 -1.87606871e+00]\n",
      " [-1.76509476e+00 -6.98609233e-01 -3.01857853e+00 -1.52520597e+00]\n",
      " [-2.24371338e+00 -9.54587817e-01  2.71702945e-01 -1.15243149e+00]\n",
      " [-1.89495075e+00 -8.23519409e-01 -3.17516947e+00 -1.62412024e+00]\n",
      " [-1.64631331e+00 -6.93832338e-01 -2.90737677e+00 -1.87623191e+00]\n",
      " [-1.55729198e+00 -5.96408069e-01 -2.75099707e+00 -1.62963891e+00]\n",
      " [-3.26786351e+00 -1.83845198e+00 -8.05414438e-01 -1.47559214e+00]\n",
      " [-1.57845032e+00 -6.18387520e-01 -2.81697083e+00 -1.72892594e+00]\n",
      " [-1.70239198e+00 -6.20473206e-01 -2.92916107e+00 -1.37624741e+00]\n",
      " [-1.72173393e+00 -6.28234744e-01 -2.94852257e+00 -1.34735787e+00]\n",
      " [-1.75877571e+00 -6.98152542e-01 -3.01242948e+00 -1.53977954e+00]\n",
      " [-1.57858419e+00 -6.20230556e-01 -2.76580977e+00 -1.63037980e+00]\n",
      " [-1.79526758e+00 -6.92574859e-01 -3.04806614e+00 -1.43998671e+00]\n",
      " [-1.59336627e+00 -5.39102793e-01 -2.63693476e+00 -1.48090601e+00]\n",
      " [-1.64616227e+00 -6.93677127e-01 -2.90724564e+00 -1.87625909e+00]\n",
      " [-1.64811909e+00 -6.95705175e-01 -2.90895271e+00 -1.87590575e+00]\n",
      " [-1.74810135e+00 -6.27765179e-01 -2.93771076e+00 -1.20682490e+00]\n",
      " [-1.64616227e+00 -6.93677127e-01 -2.90724564e+00 -1.87625909e+00]\n",
      " [-1.77421689e+00 -6.95818961e-01 -3.02759409e+00 -1.49669111e+00]\n",
      " [-1.76531041e+00 -6.98827863e-01 -3.01877880e+00 -1.52518070e+00]\n",
      " [-1.64857006e+00 -6.96173191e-01 -2.90934682e+00 -1.87582529e+00]\n",
      " [-1.71632314e+00 -5.88501096e-01 -2.90453291e+00 -1.19837606e+00]\n",
      " [-3.37895250e+00 -1.81404042e+00 -4.67290163e-01 -1.21118069e+00]\n",
      " [-1.77357078e+00 -6.95166349e-01 -3.02699232e+00 -1.49675763e+00]\n",
      " [-1.64616227e+00 -6.93677127e-01 -2.90724564e+00 -1.87625909e+00]\n",
      " [-1.78455615e+00 -6.94092274e-01 -3.03768635e+00 -1.46826482e+00]\n",
      " [-1.77853441e+00 -6.94116533e-01 -3.03185177e+00 -1.48253477e+00]\n",
      " [-1.88006222e+00 -8.26808095e-01 -3.16073608e+00 -1.66694641e+00]\n",
      " [-1.78090131e+00 -6.96507275e-01 -3.03406286e+00 -1.48230660e+00]\n",
      " [-2.46695495e+00 -9.74880934e-01 -1.80962026e-01 -1.30344069e+00]\n",
      " [-1.73308718e+00 -6.27657712e-01 -2.96014357e+00 -1.31990921e+00]\n",
      " [-3.51899600e+00 -1.91872895e+00 -1.87332928e-01 -1.00441647e+00]\n",
      " [-2.10258818e+00 -9.10831213e-01  4.66777176e-01 -1.12870169e+00]\n",
      " [-2.30420804e+00 -9.69749689e-01  1.77724481e-01 -1.17081094e+00]\n",
      " [-1.72970998e+00 -6.26772821e-01 -2.91784906e+00 -1.24817944e+00]\n",
      " [-3.23496485e+00 -1.80738103e+00 -7.76894391e-01 -1.46804261e+00]\n",
      " [-1.76444685e+00 -6.97952271e-01 -3.01798058e+00 -1.52528369e+00]\n",
      " [-3.47711587e+00 -1.87887514e+00 -2.07589447e-01 -1.02939570e+00]\n",
      " [-1.76779866e+00 -6.95355117e-01 -3.02137089e+00 -1.51112664e+00]\n",
      " [-1.77464700e+00 -6.96254790e-01 -3.02799511e+00 -1.49664652e+00]\n",
      " [-2.06023741e+00 -5.58812261e-01 -3.80034059e-01 -1.53739023e+00]\n",
      " [-1.03364789e+00 -2.82801330e-01  1.18632168e-01 -1.24994075e+00]\n",
      " [-1.15367830e+00 -5.96117735e-01  1.93313956e-01 -1.28716803e+00]\n",
      " [-2.34059882e+00 -8.83878589e-01 -1.34706497e-01 -1.30950212e+00]\n",
      " [-1.28305376e+00 -3.48437876e-01  3.20951998e-01 -1.13813925e+00]\n",
      " [-1.61667800e+00 -3.64466399e-01  5.61976314e-01 -1.13688493e+00]\n",
      " [-1.14917994e+00 -7.62008071e-01  2.21476912e-01 -1.21600449e+00]\n",
      " [-2.92409563e+00 -1.62098730e+00 -7.88364768e-01 -1.47497475e+00]\n",
      " [-1.54904521e+00 -1.52023584e-01  1.74358547e-01 -1.26057458e+00]\n",
      " [-1.15521073e+00 -5.70510387e-01  2.13652372e-01 -1.42996550e+00]\n",
      " [-2.84764600e+00 -1.53951848e+00 -7.57451117e-01 -1.47561848e+00]\n",
      " [-2.46969914e+00 -9.73246813e-01 -1.93002284e-01 -1.31027603e+00]\n",
      " [-2.55634928e+00 -1.25608051e+00 -8.79420638e-01 -1.59145355e+00]\n",
      " [-1.05430174e+00 -1.36619687e-01  1.70606345e-01 -1.35046494e+00]\n",
      " [-1.65182137e+00 -4.05500859e-01  6.04341626e-01 -1.11753392e+00]\n",
      " [-1.55008864e+00 -1.56935781e-01  3.58871818e-01 -1.12156963e+00]\n",
      " [-9.26118314e-01 -4.88524973e-01  9.47406888e-03 -1.36507583e+00]\n",
      " [-2.52584720e+00 -1.25240469e+00 -7.99427509e-01 -1.57824588e+00]\n",
      " [-2.96054935e+00 -3.13726592e+00 -1.06332731e+00  2.63915229e+00]\n",
      " [-2.39205313e+00 -9.20689583e-01 -1.53109133e-01 -1.30634832e+00]\n",
      " [-9.04004574e-01 -1.11068714e+00  2.43423373e-01 -1.24174523e+00]\n",
      " [-1.79901969e+00 -4.15598482e-01  3.47550124e-01 -1.14738429e+00]\n",
      " [ 3.58069032e-01 -3.33047271e+00 -1.17153317e-01  1.02674627e+01]\n",
      " [-1.79859734e+00 -4.47652221e-01  7.69054890e-02 -1.32347810e+00]\n",
      " [-1.40963280e+00 -2.05694735e-01  4.84976768e-01 -1.21159780e+00]\n",
      " [-1.50116754e+00 -1.45307750e-01  4.13946658e-01 -1.11860192e+00]\n",
      " [-1.14434052e+00  1.16510257e-01  2.57804751e-01 -1.23539615e+00]\n",
      " [-7.08439231e-01 -8.71584475e-01 -1.57756478e-01 -1.29649043e+00]\n",
      " [-1.18110299e+00 -5.43175340e-01  2.21020818e-01 -1.25548768e+00]\n",
      " [-2.78117871e+00 -1.45877826e+00 -9.48442638e-01 -1.56723523e+00]\n",
      " [-1.57961893e+00 -4.37065452e-01  4.54679072e-01 -1.34292817e+00]\n",
      " [-1.57961893e+00 -4.37065452e-01  4.54679072e-01 -1.34292817e+00]\n",
      " [-2.16837215e+00 -7.46324658e-01  8.69586468e-02 -1.21727335e+00]\n",
      " [-6.56067014e-01 -7.19712615e-01 -1.68886870e-01 -1.35279846e+00]\n",
      " [-2.40059590e+00 -9.84218240e-01  1.42079592e-03 -1.22121465e+00]\n",
      " [-8.87611687e-01 -7.65979350e-01 -1.00052953e-02 -1.31625390e+00]\n",
      " [-2.42569017e+00 -9.17043686e-01 -4.92370844e-01 -1.48585820e+00]\n",
      " [ 4.93438840e-01 -4.06716299e+00 -3.75507534e-01  1.14817543e+01]\n",
      " [-2.24293804e+00 -8.49501014e-01 -1.36030316e-02 -1.27357197e+00]\n",
      " [-1.55878389e+00 -2.95972973e-01  4.92200136e-01 -1.16886985e+00]\n",
      " [-1.77879989e+00 -5.27467251e-01  3.01018476e-01 -1.24877632e+00]\n",
      " [-1.08799791e+00 -1.50934011e-01  1.96643382e-01 -1.33541620e+00]\n",
      " [-2.25237632e+00 -8.04163575e-01  6.09377623e-02 -1.20519757e+00]\n",
      " [-2.30420804e+00 -9.69749689e-01  1.77724481e-01 -1.17081094e+00]\n",
      " [-2.18612766e+00 -8.10390174e-01  4.55480814e-03 -1.28126872e+00]\n",
      " [-2.22618914e+00 -8.00592184e-01  1.06977820e-01 -1.19268179e+00]\n",
      " [-1.45129895e+00 -2.24618495e-01  5.03836334e-01 -1.19251037e+00]\n",
      " [-1.54531550e+00 -2.25556672e-01  3.44472289e-01 -1.21129084e+00]\n",
      " [-2.83852458e+00 -1.39446473e+00 -6.31391764e-01 -1.44597077e+00]\n",
      " [-1.45910692e+00 -2.83876061e-01  5.18167257e-01 -1.19946015e+00]\n",
      " [-2.52902985e+00  3.32653737e+00 -5.22500849e+00 -2.14016247e+00]\n",
      " [-1.73042130e+00 -4.60660934e-01  4.07559574e-02 -1.39770007e+00]\n",
      " [-7.37775862e-03 -1.98127270e+00  4.37511384e-01  7.89737511e+00]\n",
      " [-5.90117335e-01 -5.67909479e-01  2.52528667e-01 -1.21382236e+00]\n",
      " [-4.90379810e+00  3.92107201e+00 -6.79105902e+00 -3.51706123e+00]\n",
      " [-4.82889414e-01 -5.99194944e-01 -4.71230716e-01  3.86315870e+00]\n",
      " [-6.89336002e-01 -1.29049349e+00 -2.13148743e-01 -1.35345149e+00]\n",
      " [ 1.75160900e-01 -2.16320658e+00  3.51940453e-01  8.27698517e+00]\n",
      " [ 3.86220872e-01 -3.35639977e+00  1.84645832e-01  1.06427250e+01]\n",
      " [-1.66462052e+00  2.53920579e+00 -3.53043795e+00 -1.05684423e+00]\n",
      " [-1.01827812e+00 -1.37923431e+00 -1.69704944e-01 -1.24897456e+00]\n",
      " [-3.01831436e+00  2.71273136e-01 -2.68167400e+00  2.43475184e-01]\n",
      " [-1.49862444e+00 -3.01544487e-01  7.40563869e-02 -1.44130135e+00]\n",
      " [-1.20040679e+00 -1.58617282e+00 -6.25439882e-02 -1.32795489e+00]\n",
      " [-3.69764137e+00  3.00566864e+00 -5.83301687e+00 -3.41784978e+00]\n",
      " [-1.73453581e+00 -3.82874489e-01 -1.23403013e-01 -1.46455908e+00]\n",
      " [-6.50822580e-01 -6.20532095e-01  1.10033095e-01 -1.16712701e+00]\n",
      " [-9.63022828e-01 -8.60182464e-01 -2.60763168e-02 -1.18819499e+00]\n",
      " [-1.04376054e+00  1.31648600e-01 -1.38141274e+00  3.89651656e+00]\n",
      " [-1.18110299e+00 -5.43175340e-01  2.21020818e-01 -1.25548768e+00]\n",
      " [-1.74007881e+00  6.35885000e-02 -1.81786299e+00  4.14724089e-02]\n",
      " [-1.05089068e+00 -1.41055799e+00 -1.57069594e-01 -1.25878310e+00]\n",
      " [-2.66514122e-01  2.95760930e-01  1.16919354e-01 -1.54219925e+00]\n",
      " [-1.58644652e+00 -1.32082629e+00 -3.67311925e-01 -1.49497867e+00]\n",
      " [-1.06351078e+00 -1.07060516e+00 -3.86184037e-01 -1.22207439e+00]\n",
      " [-2.30926085e+00 -8.68341923e-01 -6.64219856e-01 -1.60266542e+00]\n",
      " [-1.96677041e+00 -5.76419592e-01 -1.19680882e-01 -1.40318680e+00]\n",
      " [-7.16863513e-01 -8.75798821e-01  8.36734772e-02 -1.19814348e+00]\n",
      " [-2.46898365e+00 -9.40163851e-01 -3.74651134e-01 -1.41945076e+00]\n",
      " [-1.58913970e+00 -1.58445776e-01 -3.06473285e-01 -1.58795381e+00]\n",
      " [-9.87624526e-01 -1.18508804e+00 -3.43185514e-01 -1.33831835e+00]\n",
      " [-1.36440682e+00  1.11991279e-01 -4.12078619e-01 -1.69711554e+00]\n",
      " [-2.46695495e+00 -9.74880934e-01 -1.80962026e-01 -1.30344069e+00]\n",
      " [-8.13002169e-01 -2.40616694e-01 -5.67822158e-02 -1.34754050e+00]\n",
      " [-1.50385475e+00 -2.67854273e-01  1.31040812e-04 -1.46629024e+00]\n",
      " [-2.31832176e-01 -7.93103039e-01 -2.60078371e-01  5.25393105e+00]\n",
      " [-2.59214354e+00  2.06888843e+00 -3.80452967e+00 -1.97222292e+00]\n",
      " [-6.44303620e-01 -6.97133780e-01  6.25532866e-03 -1.16859198e+00]\n",
      " [-1.93051863e+00 -5.79300523e-01 -4.93018031e-02 -1.37903965e+00]\n",
      " [-1.75111866e+00 -3.22717607e-01 -2.62534261e-01 -1.53184104e+00]\n",
      " [-1.62801504e+00 -2.60614097e-01 -1.88909739e-01 -1.51747572e+00]\n",
      " [-2.38326454e+00 -8.99586916e-01 -5.64744949e-01 -1.53396344e+00]\n",
      " [-3.19331598e+00  5.67708731e-01 -2.98565292e+00  2.11959317e-01]\n",
      " [-3.71472430e+00  3.18282986e+00 -5.63801193e+00 -2.80835199e+00]\n",
      " [-2.42569017e+00 -9.17043686e-01 -4.92370844e-01 -1.48585820e+00]\n",
      " [-3.60220933e+00  3.68075275e+00 -5.29755354e+00 -2.30701447e-01]\n",
      " [-1.78752661e+00 -5.00551879e-01  2.83554494e-02 -1.38560748e+00]\n",
      " [-1.76855516e+00 -1.15242696e+00 -7.49130011e-01 -1.48311067e+00]\n",
      " [-1.23072875e+00 -9.49510336e-01 -7.94257164e-01 -2.98942387e-01]\n",
      " [-1.73877454e+00 -4.61390257e-01  2.85377204e-02 -1.40032852e+00]]\n",
      "\n",
      "Denormalized Reconstructed Data:\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0   4.362079   2.790939  -1.617088   0.015607\n",
      "1   3.937713   2.679059   4.148660   0.270492\n",
      "2   4.359269   2.792079  -1.622977   0.026284\n",
      "3   4.367703   2.791225  -1.605701   0.004626\n",
      "4   4.361897   2.790848  -1.617445   0.015624\n",
      "\n",
      "Ground Values (Before Processing, At the End):\n",
      "   feature_0  feature_1  feature_2  feature_3\n",
      "0        5.1        3.5        1.4        0.2\n",
      "1        4.9        3.0        1.4        0.2\n",
      "2        4.7        3.2        1.3        0.2\n",
      "3        4.6        3.1        1.5        0.2\n",
      "4        5.0        3.6        1.4        0.2\n",
      "\n",
      "Root Mean Squared Error (RMSE): 2.1034321851239155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Iris dataset (150 samples, 4 features)\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(data.shape[1])])\n",
    "\n",
    "# Print the original data before introducing missing values\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Store a copy of the original data for later comparison\n",
    "ground_values = df.copy()\n",
    "\n",
    "# Introduce artificial missing values\n",
    "missing_fraction = 0.3  # Adjust the fraction of missing values\n",
    "mask = np.random.rand(*data.shape) < missing_fraction\n",
    "df[mask] = np.nan\n",
    "\n",
    "# Print the input dataset with missing values\n",
    "print(\"\\nInput Data with Missing Values:\")\n",
    "print(df.head())\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print('\\nAfter Normalizing Input Data:')\n",
    "print(df.head())\n",
    "\n",
    "# Fill missing values with zero placeholder\n",
    "df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "\n",
    "print(\"\\nFilled Missing Values with Zero Placeholder:\")\n",
    "print(df.head())\n",
    "\n",
    "# Pretrain the TabNet model\n",
    "pretrained_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax',\n",
    "    n_d=32,  # Increase the number of decision steps\n",
    "    n_a=32   # Increase the number of features shared\n",
    ")\n",
    "\n",
    "max_epochs = 100\n",
    "pretrained_model.fit(\n",
    "    df[numeric_cols].values,\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "print(\"\\nPretrained TabNet Model:\")\n",
    "\n",
    "def tabnet_recon(df, network, df_mean=0, df_std=1):\n",
    "    df_train = df.copy()\n",
    "    df_train[numeric_cols] = scaler.transform(df_train[numeric_cols])\n",
    "\n",
    "    # Convert input data to tensors for use in the TabNet network\n",
    "    input_data = torch.tensor(df_train[numeric_cols].values, dtype=torch.float32)\n",
    "\n",
    "    # Pass the input data through the TabNet network\n",
    "    results = network.predict(input_data)\n",
    "\n",
    "    # Handle potential tuple output\n",
    "    if isinstance(results, tuple):\n",
    "        results = results[0]  # Use the first element of the tuple\n",
    "\n",
    "    # Denormalize the reconstructed data\n",
    "    df_na_tab = (results * df_std) + df_mean\n",
    "\n",
    "    # Initialize a new DataFrame with the same structure as df\n",
    "    df_rec_tab = df.copy()\n",
    "\n",
    "    # Convert numeric_cols to a list\n",
    "    numeric_cols_list = list(numeric_cols)\n",
    "\n",
    "    for col in numeric_cols_list:\n",
    "        df_rec_tab[col] = df_na_tab[:, numeric_cols_list.index(col)]\n",
    "\n",
    "    return df_rec_tab\n",
    "\n",
    "# Extract true missing values before filling\n",
    "true_missing_values = df[numeric_cols].values\n",
    "\n",
    "print('\\nTrue Missing Values:')\n",
    "print(true_missing_values)\n",
    "\n",
    "# Reconstruct missing values using the pretrained model\n",
    "reconstructed_data = tabnet_recon(df, network=pretrained_model)\n",
    "\n",
    "print('\\nReconstructed Data:')\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Extract imputed values\n",
    "imputed_values = reconstructed_data[numeric_cols].values\n",
    "\n",
    "print('\\nImputed Values:')\n",
    "print(imputed_values)\n",
    "\n",
    "# Denormalize the reconstructed data\n",
    "reconstructed_data[numeric_cols] = scaler.inverse_transform(reconstructed_data)\n",
    "\n",
    "print(\"\\nDenormalized Reconstructed Data:\")\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Print the ground values again (before processing) at the end\n",
    "print(\"\\nGround Values (Before Processing, At the End):\")\n",
    "print(ground_values.head())\n",
    "\n",
    "# Compare the denormalized reconstructed data with the original input data\n",
    "# Calculate RMSE\n",
    "rmse = math.sqrt(mean_squared_error(ground_values[numeric_cols].values, reconstructed_data[numeric_cols].values))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f612e",
   "metadata": {},
   "source": [
    "# Synthetic data (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e15eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.764052   0.400157   0.978738   2.240893   1.867558  -0.977278   \n",
      "1   0.333674   1.494079  -0.205158   0.313068  -0.854096  -2.552990   \n",
      "2   0.154947   0.378163  -0.887786  -1.980796  -0.347912   0.156349   \n",
      "3  -0.438074  -1.252795   0.777490  -1.613898  -0.212740  -0.895467   \n",
      "4  -0.672460  -0.359553  -0.813146  -1.726283   0.177426  -0.401781   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0   0.950088  -0.151357  -0.103219   0.410599    0.144044    1.454274   \n",
      "1   0.653619   0.864436  -0.742165   2.269755   -1.454366    0.045759   \n",
      "2   1.230291   1.202380  -0.387327  -0.302303   -1.048553   -1.420018   \n",
      "3   0.386902  -0.510805  -1.180632  -0.028182    0.428332    0.066517   \n",
      "4  -1.630198   0.462782  -0.907298   0.051945    0.729091    0.128983   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0    0.761038    0.121675    0.443863  \n",
      "1   -0.187184    1.532779    1.469359  \n",
      "2   -1.706270    1.950775   -0.509652  \n",
      "3    0.302472   -0.634322   -0.362741  \n",
      "4    1.139401   -1.234826    0.402342  \n",
      "\n",
      "Input Data with Missing Values:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.764052        NaN   0.978738        NaN   1.867558        NaN   \n",
      "1        NaN        NaN  -0.205158   0.313068  -0.854096  -2.552990   \n",
      "2        NaN   0.378163  -0.887786  -1.980796  -0.347912   0.156349   \n",
      "3  -0.438074  -1.252795   0.777490  -1.613898  -0.212740  -0.895467   \n",
      "4        NaN  -0.359553  -0.813146  -1.726283        NaN  -0.401781   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0        NaN  -0.151357  -0.103219   0.410599    0.144044         NaN   \n",
      "1   0.653619   0.864436  -0.742165   2.269755   -1.454366    0.045759   \n",
      "2   1.230291   1.202380        NaN  -0.302303   -1.048553         NaN   \n",
      "3        NaN  -0.510805  -1.180632  -0.028182    0.428332    0.066517   \n",
      "4  -1.630198   0.462782  -0.907298        NaN    0.729091    0.128983   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0    0.761038    0.121675         NaN  \n",
      "1   -0.187184    1.532779         NaN  \n",
      "2         NaN    1.950775   -0.509652  \n",
      "3    0.302472         NaN   -0.362741  \n",
      "4         NaN         NaN    0.402342  \n",
      "\n",
      "After Normalizing Input Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.799233        NaN   1.010263        NaN   1.935665        NaN   \n",
      "1        NaN        NaN  -0.190022   0.323549  -0.876502  -2.523270   \n",
      "2        NaN   0.350250  -0.882099  -2.045601  -0.353484   0.168557   \n",
      "3  -0.412076  -1.256225   0.806230  -1.666660  -0.213817  -0.876460   \n",
      "4        NaN  -0.376392  -0.806426  -1.782734        NaN  -0.385966   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0        NaN  -0.162386  -0.081088   0.467820    0.163418         NaN   \n",
      "1   0.672369   0.860295  -0.714579   2.319326   -1.450481    0.039726   \n",
      "2   1.263375   1.200531        NaN  -0.242148   -1.040736         NaN   \n",
      "3        NaN  -0.524272  -1.149302   0.030845    0.450462    0.060579   \n",
      "4  -1.668214   0.455918  -0.878302        NaN    0.754135    0.123331   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0    0.745166    0.166207         NaN  \n",
      "1   -0.191286    1.566410         NaN  \n",
      "2         NaN    1.981178   -0.543701  \n",
      "3    0.292292         NaN   -0.392418  \n",
      "4         NaN         NaN    0.395431  \n",
      "\n",
      "Filled Missing Values with Zero Placeholder:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.799233   0.000000   1.010263   0.000000   1.935665   0.000000   \n",
      "1   0.000000   0.000000  -0.190022   0.323549  -0.876502  -2.523270   \n",
      "2   0.000000   0.350250  -0.882099  -2.045601  -0.353484   0.168557   \n",
      "3  -0.412076  -1.256225   0.806230  -1.666660  -0.213817  -0.876460   \n",
      "4   0.000000  -0.376392  -0.806426  -1.782734   0.000000  -0.385966   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0   0.000000  -0.162386  -0.081088   0.467820    0.163418    0.000000   \n",
      "1   0.672369   0.860295  -0.714579   2.319326   -1.450481    0.039726   \n",
      "2   1.263375   1.200531   0.000000  -0.242148   -1.040736    0.000000   \n",
      "3   0.000000  -0.524272  -1.149302   0.030845    0.450462    0.060579   \n",
      "4  -1.668214   0.455918  -0.878302   0.000000    0.754135    0.123331   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0    0.745166    0.166207    0.000000  \n",
      "1   -0.191286    1.566410    0.000000  \n",
      "2    0.000000    1.981178   -0.543701  \n",
      "3    0.292292    0.000000   -0.392418  \n",
      "4    0.000000    0.000000    0.395431  \n",
      "Device used : cpu\n",
      "No early stopping will be performed, last training weights will be used.\n",
      "epoch 0  | loss: 3.6044  |  0:00:03s\n",
      "epoch 1  | loss: 1.80295 |  0:00:07s\n",
      "epoch 2  | loss: 1.43979 |  0:00:09s\n",
      "epoch 3  | loss: 1.18752 |  0:00:12s\n",
      "epoch 4  | loss: 1.1174  |  0:00:17s\n",
      "epoch 5  | loss: 1.0795  |  0:00:20s\n",
      "epoch 6  | loss: 1.05037 |  0:00:26s\n",
      "epoch 7  | loss: 1.04097 |  0:00:30s\n",
      "epoch 8  | loss: 1.03151 |  0:00:36s\n",
      "epoch 9  | loss: 1.02713 |  0:00:41s\n",
      "epoch 10 | loss: 0.9949  |  0:00:44s\n",
      "epoch 11 | loss: 1.01961 |  0:00:47s\n",
      "epoch 12 | loss: 1.033   |  0:00:52s\n",
      "epoch 13 | loss: 1.02599 |  0:00:57s\n",
      "epoch 14 | loss: 0.9991  |  0:01:01s\n",
      "epoch 15 | loss: 0.98843 |  0:01:04s\n",
      "epoch 16 | loss: 1.02135 |  0:01:10s\n",
      "epoch 17 | loss: 1.01403 |  0:01:12s\n",
      "epoch 18 | loss: 1.01376 |  0:01:14s\n",
      "epoch 19 | loss: 0.99627 |  0:01:16s\n",
      "epoch 20 | loss: 0.99436 |  0:01:19s\n",
      "epoch 21 | loss: 1.00175 |  0:01:22s\n",
      "epoch 22 | loss: 0.98691 |  0:01:27s\n",
      "epoch 23 | loss: 1.00267 |  0:01:31s\n",
      "epoch 24 | loss: 1.00086 |  0:01:36s\n",
      "epoch 25 | loss: 1.003   |  0:01:40s\n",
      "epoch 26 | loss: 1.00299 |  0:01:45s\n",
      "epoch 27 | loss: 0.98843 |  0:01:50s\n",
      "epoch 28 | loss: 1.02517 |  0:01:53s\n",
      "epoch 29 | loss: 0.98468 |  0:01:57s\n",
      "epoch 30 | loss: 0.98982 |  0:02:00s\n",
      "epoch 31 | loss: 0.99791 |  0:02:03s\n",
      "epoch 32 | loss: 0.991   |  0:02:06s\n",
      "epoch 33 | loss: 1.00134 |  0:02:09s\n",
      "epoch 34 | loss: 0.98304 |  0:02:11s\n",
      "epoch 35 | loss: 0.99487 |  0:02:15s\n",
      "epoch 36 | loss: 1.01639 |  0:02:17s\n",
      "epoch 37 | loss: 0.99354 |  0:02:20s\n",
      "epoch 38 | loss: 0.99279 |  0:02:23s\n",
      "epoch 39 | loss: 0.99388 |  0:02:26s\n",
      "epoch 40 | loss: 1.00554 |  0:02:29s\n",
      "epoch 41 | loss: 1.0085  |  0:02:31s\n",
      "epoch 42 | loss: 0.992   |  0:02:33s\n",
      "epoch 43 | loss: 1.0228  |  0:02:37s\n",
      "epoch 44 | loss: 0.98273 |  0:02:42s\n",
      "epoch 45 | loss: 0.99102 |  0:02:46s\n",
      "epoch 46 | loss: 1.01298 |  0:02:51s\n",
      "epoch 47 | loss: 0.97685 |  0:02:55s\n",
      "epoch 48 | loss: 1.00284 |  0:03:00s\n",
      "epoch 49 | loss: 0.99458 |  0:03:03s\n",
      "\n",
      "Pretrained TabNet Model:\n",
      "\n",
      "True Missing Values:\n",
      "[[ 1.79923303  0.          1.01026339 ...  0.74516649  0.16620714\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.19002176 ... -0.19128579  1.56641049\n",
      "   0.        ]\n",
      " [ 0.          0.35024965 -0.88209899 ...  0.          1.98117763\n",
      "  -0.54370077]\n",
      " ...\n",
      " [-0.8524186   0.9012407   1.16765649 ...  0.69885871  0.27019602\n",
      "   0.        ]\n",
      " [-1.07515779  1.19102543  0.         ... -0.03203883 -0.40412128\n",
      "   0.        ]\n",
      " [ 0.00276643 -0.56158698  0.8497285  ...  0.05508806  0.21177983\n",
      "  -0.42924687]]\n",
      "\n",
      "Reconstructed Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.028739   0.005660  -0.029242   0.013392   0.022723   0.014795   \n",
      "1  -0.016251  -0.000098  -0.033618  -0.057563   0.031042  -0.041775   \n",
      "2   0.035617  -0.001006   0.007946   0.011640  -0.035836  -0.037607   \n",
      "3   0.000717   0.011179  -0.000889   0.013194   0.010675   0.003320   \n",
      "4   0.006038  -0.016257  -0.006187  -0.008898  -0.002653  -0.000846   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0  -0.012295   0.040736   0.020143   0.006873    0.018393    0.034341   \n",
      "1   0.027605   0.037936  -0.002036   0.048915   -0.064654    0.057992   \n",
      "2  -0.008577   0.035260   0.007880  -0.034520    0.001753    0.005533   \n",
      "3  -0.001457   0.000899  -0.008401   0.004969    0.011807   -0.001857   \n",
      "4   0.007003   0.017901  -0.003087   0.004853   -0.011609    0.021031   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0   -0.022967   -0.008479   -0.037331  \n",
      "1   -0.009102   -0.006134    0.063561  \n",
      "2   -0.058731   -0.030321    0.063330  \n",
      "3    0.018290    0.018713   -0.026441  \n",
      "4   -0.018796   -0.023260    0.040962  \n",
      "\n",
      "Imputed Values:\n",
      "[[ 2.8738936e-02  5.6600319e-03 -2.9242272e-02 ... -2.2967240e-02\n",
      "  -8.4790792e-03 -3.7330721e-02]\n",
      " [-1.6251490e-02 -9.7889453e-05 -3.3617642e-02 ... -9.1022272e-03\n",
      "  -6.1336532e-03  6.3560963e-02]\n",
      " [ 3.5617374e-02 -1.0058405e-03  7.9458719e-03 ... -5.8730867e-02\n",
      "  -3.0321348e-02  6.3329905e-02]\n",
      " ...\n",
      " [ 2.5467359e-02 -2.1510432e-03  3.2716533e-03 ... -7.1137706e-03\n",
      "  -3.5913907e-02  7.5786211e-02]\n",
      " [ 3.1390637e-02 -2.0085912e-02  3.8186589e-03 ... -4.5788586e-03\n",
      "  -1.3184583e-02  8.5349970e-02]\n",
      " [ 3.8642822e-05  6.0244801e-04 -4.7927613e-05 ...  9.8562520e-04\n",
      "   1.0084292e-03 -1.4248891e-03]]\n",
      "\n",
      "Denormalized Reconstructed Data:\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   0.000910   0.028321  -0.046574   0.012767   0.016186   0.001587   \n",
      "1  -0.043893   0.022476  -0.050890  -0.055934   0.024237  -0.055351   \n",
      "2   0.007760   0.021554  -0.009894   0.011070  -0.040488  -0.051156   \n",
      "3  -0.026995   0.033925  -0.018608   0.012575   0.004526  -0.009963   \n",
      "4  -0.021696   0.006070  -0.023833  -0.008816  -0.008373  -0.014156   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0  -0.014440   0.050397  -0.001116  -0.052253    0.000410    0.040398   \n",
      "1   0.024491   0.047615  -0.023486  -0.010038   -0.081840    0.063942   \n",
      "2  -0.010812   0.044958  -0.013484  -0.093817   -0.016071    0.011722   \n",
      "3  -0.003866   0.010829  -0.029906  -0.054165   -0.006113    0.004366   \n",
      "4   0.004389   0.027716  -0.024546  -0.054282   -0.029304    0.027149   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0   -0.016750   -0.054371   -0.017915  \n",
      "1   -0.002711   -0.052007    0.080062  \n",
      "2   -0.052963   -0.076383    0.079837  \n",
      "3    0.025026   -0.026967   -0.007340  \n",
      "4   -0.012526   -0.069267    0.058115  \n",
      "\n",
      "Ground Values (Before Processing, At the End):\n",
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0   1.764052   0.400157   0.978738   2.240893   1.867558  -0.977278   \n",
      "1   0.333674   1.494079  -0.205158   0.313068  -0.854096  -2.552990   \n",
      "2   0.154947   0.378163  -0.887786  -1.980796  -0.347912   0.156349   \n",
      "3  -0.438074  -1.252795   0.777490  -1.613898  -0.212740  -0.895467   \n",
      "4  -0.672460  -0.359553  -0.813146  -1.726283   0.177426  -0.401781   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11  \\\n",
      "0   0.950088  -0.151357  -0.103219   0.410599    0.144044    1.454274   \n",
      "1   0.653619   0.864436  -0.742165   2.269755   -1.454366    0.045759   \n",
      "2   1.230291   1.202380  -0.387327  -0.302303   -1.048553   -1.420018   \n",
      "3   0.386902  -0.510805  -1.180632  -0.028182    0.428332    0.066517   \n",
      "4  -1.630198   0.462782  -0.907298   0.051945    0.729091    0.128983   \n",
      "\n",
      "   feature_12  feature_13  feature_14  \n",
      "0    0.761038    0.121675    0.443863  \n",
      "1   -0.187184    1.532779    1.469359  \n",
      "2   -1.706270    1.950775   -0.509652  \n",
      "3    0.302472   -0.634322   -0.362741  \n",
      "4    1.139401   -1.234826    0.402342  \n",
      "\n",
      "Root Mean Squared Error (RMSE): 0.9942089019931728\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Create a random dataset (e.g., 500 samples, 10 features)\n",
    "np.random.seed(0)\n",
    "n_samples = 2500\n",
    "n_features = 15\n",
    "data = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "\n",
    "# Print the original data before introducing missing values\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Store a copy of the original data for later comparison\n",
    "ground_values = df.copy()\n",
    "\n",
    "# Introduce artificial missing values\n",
    "missing_fraction = 0.3  # Adjust the fraction of missing values\n",
    "mask = np.random.rand(n_samples, n_features) < missing_fraction\n",
    "df[mask] = np.nan\n",
    "\n",
    "# Print the input dataset with missing values\n",
    "print(\"\\nInput Data with Missing Values:\")\n",
    "print(df.head())\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print('\\nAfter Normalizing Input Data:')\n",
    "print(df.head())\n",
    "\n",
    "# Fill missing values with zero placeholder\n",
    "df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "\n",
    "print(\"\\nFilled Missing Values with Zero Placeholder:\")\n",
    "print(df.head())\n",
    "\n",
    "# Pretrain the TabNet model\n",
    "pretrained_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax',\n",
    "    n_d=32,  # Increase the number of decision steps\n",
    "    n_a=32   # Increase the number of features shared\n",
    ")\n",
    "\n",
    "max_epochs = 50\n",
    "pretrained_model.fit(\n",
    "    df[numeric_cols].values,\n",
    "    max_epochs=max_epochs\n",
    ")\n",
    "print(\"\\nPretrained TabNet Model:\")\n",
    "\n",
    "def tabnet_recon(df, network, df_mean=0, df_std=1):\n",
    "    df_train = df.copy()\n",
    "    df_train[numeric_cols] = scaler.transform(df_train[numeric_cols])\n",
    "\n",
    "    # Convert input data to tensors for use in the TabNet network\n",
    "    input_data = torch.tensor(df_train[numeric_cols].values, dtype=torch.float32)\n",
    "\n",
    "    # Pass the input data through the TabNet network\n",
    "    results = network.predict(input_data)\n",
    "\n",
    "    # Handle potential tuple output\n",
    "    if isinstance(results, tuple):\n",
    "        results = results[0]  # Use the first element of the tuple\n",
    "\n",
    "    # Denormalize the reconstructed data\n",
    "    df_na_tab = (results * df_std) + df_mean\n",
    "\n",
    "    # Initialize a new DataFrame with the same structure as df\n",
    "    df_rec_tab = df.copy()\n",
    "\n",
    "    # Convert numeric_cols to a list\n",
    "    numeric_cols_list = list(numeric_cols)\n",
    "\n",
    "    # Only update non-missing values, leave missing values as zeros\n",
    "    for col in numeric_cols_list:\n",
    "        df_rec_tab[col] = df_na_tab[:, numeric_cols_list.index(col)]\n",
    "\n",
    "    return df_rec_tab\n",
    "\n",
    "# Extract true missing values before filling\n",
    "true_missing_values = df[numeric_cols].values\n",
    "\n",
    "print('\\nTrue Missing Values:')\n",
    "print(true_missing_values)\n",
    "\n",
    "# Reconstruct missing values using the pretrained model\n",
    "reconstructed_data = tabnet_recon(df, network=pretrained_model)\n",
    "\n",
    "print('\\nReconstructed Data:')\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Extract imputed values\n",
    "imputed_values = reconstructed_data[numeric_cols].values\n",
    "\n",
    "print('\\nImputed Values:')\n",
    "print(imputed_values)\n",
    "\n",
    "# Denormalize the reconstructed data\n",
    "reconstructed_data[numeric_cols] = scaler.inverse_transform(reconstructed_data[numeric_cols])\n",
    "\n",
    "print(\"\\nDenormalized Reconstructed Data:\")\n",
    "print(reconstructed_data.head())\n",
    "\n",
    "# Print the ground values again (before processing) at the end\n",
    "print(\"\\nGround Values (Before Processing, At the End):\")\n",
    "print(ground_values.head())\n",
    "\n",
    "# Compare the denormalized reconstructed data with the original input data\n",
    "# Calculate RMSE\n",
    "rmse = math.sqrt(mean_squared_error(ground_values[numeric_cols].values, reconstructed_data[numeric_cols].values))\n",
    "print(\"\\nRoot Mean Squared Error (RMSE):\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
