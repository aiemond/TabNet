{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP23A6jHfKvzZVoKGgC/vl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiemond/TabNet/blob/main/TabNetImputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QswECexkzYQd",
        "outputId": "ddc8ccd1-9bae-492e-c251-8641673d63ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 3.71432 |  0:00:00s\n",
            "epoch 1  | loss: 2.00397 |  0:00:00s\n",
            "epoch 2  | loss: 1.38268 |  0:00:00s\n",
            "epoch 3  | loss: 1.1753  |  0:00:00s\n",
            "epoch 4  | loss: 1.08561 |  0:00:00s\n",
            "epoch 5  | loss: 1.04796 |  0:00:01s\n",
            "epoch 6  | loss: 1.02771 |  0:00:01s\n",
            "epoch 7  | loss: 1.00867 |  0:00:01s\n",
            "epoch 8  | loss: 1.01442 |  0:00:01s\n",
            "epoch 9  | loss: 1.01794 |  0:00:01s\n",
            "MAE: 0.6471541921315724\n",
            "R-squared: -0.0024228582490715134\n",
            "RMSE: 0.896584038719793\n",
            "Original Data:\n",
            "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
            "0  0.000000 -0.401434 -0.683793 -0.161647  0.369118  0.175104 -1.919698   \n",
            "1  0.000000 -0.430877 -0.311414  0.000000  0.302928  0.000000 -1.018288   \n",
            "2  0.636453 -1.763517  0.000000  0.045774 -0.939967 -0.422877  0.000000   \n",
            "3  1.514330 -0.308434  0.103817  0.927079  0.604787  0.002869  0.154902   \n",
            "4 -0.247943  0.746892  0.000000  0.000000  0.000000  0.492921  1.006554   \n",
            "\n",
            "   feature8  feature9  feature10  ...  feature17  feature18  feature19  \\\n",
            "0  0.929043 -0.503063   1.051672  ...   0.636948   1.582850   0.981565   \n",
            "1  0.000000  0.991237  -0.768557  ...  -0.302676   0.000000  -0.370636   \n",
            "2  0.355361 -0.227597   1.200468  ...   0.000000  -1.414535  -0.583613   \n",
            "3 -0.250667  0.063054   0.000000  ...  -0.184520   0.714317   0.953541   \n",
            "4 -1.069553  0.693987   0.859109  ...   0.490201   0.007114  -2.770081   \n",
            "\n",
            "   feature20  feature21  feature22  feature23  feature24  feature25  subtype  \n",
            "0  -0.489842   0.000000  -0.049749   0.803447  -0.692260  -0.198721        B  \n",
            "1  -0.927065   0.000000   0.253228  -0.046028   0.000000   0.408373        C  \n",
            "2  -0.090813   0.561407   0.221720   0.000000  -1.179133   0.763800        A  \n",
            "3   0.000000  -0.632926   0.673290   0.171003  -1.187807  -1.172263        C  \n",
            "4  -0.211449  -0.341174  -0.935622   0.000000   0.000000   0.000000        B  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "\n",
            "Reconstructed Data:\n",
            "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
            "0  0.021787  0.018765  0.014452 -0.028471  0.020138  0.052139 -0.015820   \n",
            "1 -0.011063  0.000797 -0.032432  0.013964 -0.056399  0.012827 -0.036220   \n",
            "2  0.000850  0.013616 -0.011991  0.013232 -0.023846  0.009441 -0.031472   \n",
            "3  0.009611  0.026800 -0.027695 -0.025583 -0.011715  0.059991 -0.021199   \n",
            "4  0.008562  0.011952  0.012134 -0.044590  0.009306  0.057592 -0.015285   \n",
            "\n",
            "   feature8  feature9  feature10  ...  feature17  feature18  feature19  \\\n",
            "0  0.030275 -0.001548   0.014456  ...   0.013310  -0.040792  -0.010027   \n",
            "1 -0.030661 -0.036643  -0.033995  ...  -0.032973  -0.074142  -0.003909   \n",
            "2 -0.055295 -0.015311  -0.005440  ...  -0.017707  -0.031447  -0.004082   \n",
            "3  0.070094 -0.051655   0.012298  ...   0.003170  -0.071694   0.002010   \n",
            "4  0.054523  0.022002  -0.045578  ...  -0.006194  -0.062986  -0.023909   \n",
            "\n",
            "   feature20  feature21  feature22  feature23  feature24  feature25  subtype  \n",
            "0   0.001802   0.020129  -0.032039  -0.004658   0.012809  -0.002269        B  \n",
            "1  -0.005566  -0.001189  -0.045280  -0.016345   0.008294   0.015718        C  \n",
            "2   0.011468   0.030595  -0.014899  -0.001509  -0.008492   0.019536        A  \n",
            "3  -0.008581  -0.016107  -0.050766  -0.012936   0.022930  -0.028966        C  \n",
            "4   0.006261   0.013826  -0.033186  -0.016094  -0.003301   0.008352        B  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "\n",
        "# larger example dataset with missing values\n",
        "np.random.seed(42)\n",
        "num_samples = 5000\n",
        "num_features = 25\n",
        "data = {\n",
        "    f'feature{i}': np.random.normal(size=num_samples) for i in range(1, num_features + 1)\n",
        "}\n",
        "data['subtype'] = np.random.choice(['A', 'B', 'C'], size=num_samples)\n",
        "\n",
        "# Introduce random missing values\n",
        "missing_mask = np.random.rand(num_samples, num_features) < 0.2\n",
        "for col in data.keys():\n",
        "    if col != 'subtype':\n",
        "        data[col][missing_mask[:, int(col[-1]) - 1]] = np.nan\n",
        "\n",
        "omicMiss = pd.DataFrame(data)\n",
        "\n",
        "# Normalize the dataset\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = [f'feature{i}' for i in range(1, num_features + 1)]\n",
        "omicMiss[numeric_cols] = scaler.fit_transform(omicMiss[numeric_cols])\n",
        "\n",
        "# Handle missing values by filling NaNs with a specific value\n",
        "missing_value_placeholder = 0\n",
        "omicMiss.fillna(missing_value_placeholder, inplace=True)\n",
        "\n",
        "# Pretrain the TabNet model\n",
        "pretrained_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax'\n",
        ")\n",
        "\n",
        "max_epochs = 10\n",
        "pretrained_model.fit(\n",
        "    omicMiss[numeric_cols].values,\n",
        "    max_epochs=max_epochs\n",
        ")\n",
        "\n",
        "# Define the tabnet_recon function\n",
        "\n",
        "def tabnet_recon(omicMiss, network, omicMissMean=0, omicMissSd=1):\n",
        "    omicMissTrain = omicMiss.copy()\n",
        "    omicMissTrain[numeric_cols] = scaler.transform(omicMissTrain[numeric_cols])\n",
        "\n",
        "    # Convert input data to tensors for use in the TabNet network\n",
        "    inputData = torch.tensor(omicMissTrain[numeric_cols].values, dtype=torch.float32)\n",
        "\n",
        "    # Pass the input data through the TabNet network\n",
        "    results = network.predict(inputData)\n",
        "\n",
        "    # Handle potential tuple output\n",
        "    if isinstance(results, tuple):\n",
        "        results = results[0]  # Use the first element of the tuple\n",
        "\n",
        "    # Denormalize the reconstructed data\n",
        "    omicNa_tab = (results * omicMissSd) + omicMissMean\n",
        "\n",
        "    # Combine reconstructed data with original categorical column\n",
        "    omicNa_tab = pd.DataFrame(omicNa_tab, columns=numeric_cols)\n",
        "    omicNa_tab['subtype'] = omicMiss['subtype']\n",
        "\n",
        "    # Patch the reconstructed data into the original data with missing values\n",
        "    omicRec_tab = omicMiss.copy()\n",
        "    omicRec_tab.update(omicNa_tab)\n",
        "\n",
        "    return omicRec_tab\n",
        "\n",
        "\n",
        "# Extract true missing values before filling\n",
        "true_missing_values = omicMiss[numeric_cols].values\n",
        "\n",
        "# Reconstruct missing values using the pretrained model\n",
        "reconstructed_data = tabnet_recon(omicMiss, network=pretrained_model)\n",
        "\n",
        "# Extract imputed values\n",
        "imputed_values = reconstructed_data[numeric_cols].values\n",
        "\n",
        "# Calculate MAE, R-squared, and RMSE\n",
        "mae = np.mean(np.abs(imputed_values - true_missing_values))\n",
        "total_variation = np.sum((true_missing_values - np.mean(true_missing_values)) ** 2)\n",
        "residual_variation = np.sum((true_missing_values - imputed_values) ** 2)\n",
        "r_squared = 1 - (residual_variation / total_variation)\n",
        "rmse = np.sqrt(np.mean((imputed_values - true_missing_values) ** 2))\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Print original and reconstructed data (only printing a subset)\n",
        "print(\"Original Data:\")\n",
        "print(omicMiss.head())\n",
        "print(\"\\nReconstructed Data:\")\n",
        "print(reconstructed_data.head())\n"
      ]
    }
  ]
}