{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEtWY0eElQb4VK7zNNmCkp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiemond/TabNet/blob/main/TabNetImp6000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QswECexkzYQd",
        "outputId": "d81a9656-438d-44ca-9cdb-7a6ca83eec3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 3.49529 |  0:00:00s\n",
            "epoch 1  | loss: 1.70596 |  0:00:00s\n",
            "epoch 2  | loss: 1.21633 |  0:00:00s\n",
            "epoch 3  | loss: 1.08369 |  0:00:01s\n",
            "epoch 4  | loss: 1.03627 |  0:00:01s\n",
            "epoch 5  | loss: 1.02045 |  0:00:02s\n",
            "epoch 6  | loss: 1.01024 |  0:00:02s\n",
            "epoch 7  | loss: 1.0123  |  0:00:02s\n",
            "epoch 8  | loss: 1.00933 |  0:00:03s\n",
            "epoch 9  | loss: 1.00401 |  0:00:03s\n",
            "MAE: 0.6448486690276234\n",
            "R-squared: -0.0036931202033747557\n",
            "RMSE: 0.8960306105649233\n",
            "Original Data:\n",
            "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
            "0  0.494949 -1.099798  1.128279  0.326407 -0.670756 -1.933324  0.570959   \n",
            "1  0.000000  0.000000 -1.886265 -0.774835 -0.713365  0.000000 -0.167484   \n",
            "2  0.645647  0.000000 -0.355017  0.695275  1.435045 -0.563468  0.406604   \n",
            "3  1.519386 -0.532835 -0.072559 -0.584177  1.875941  0.000000  0.352946   \n",
            "4 -0.234580 -0.198472 -0.015731  0.000000  0.000000  1.020334  0.000000   \n",
            "\n",
            "   feature8  feature9  feature10  ...  feature22  feature23  feature24  \\\n",
            "0  0.000000  0.593633   0.691191  ...   0.329052  -0.153546   0.836515   \n",
            "1  0.872459  0.000000  -0.309113  ...   0.000000  -0.112310   0.030878   \n",
            "2 -0.244421  0.000000   0.211356  ...   0.000000   0.744865   1.295291   \n",
            "3  0.026821 -0.232771  -0.503793  ...  -0.342638  -1.896342  -0.549217   \n",
            "4 -0.075989 -0.028616   0.000000  ...  -0.584856  -1.483633   0.000000   \n",
            "\n",
            "   feature25  feature26  feature27  feature28  feature29  feature30  subtype  \n",
            "0  -1.913336   1.400235  -0.828423   0.000000  -0.451695   0.072339        B  \n",
            "1   1.072366   0.000000   1.298234  -2.830404   0.000000   0.788878        C  \n",
            "2   1.362124  -1.097815  -0.605417   2.250025   0.000000   0.795673        C  \n",
            "3   0.350586   0.000000  -0.519338  -0.502065   0.541669  -2.519584        A  \n",
            "4   0.000000  -0.110078   0.000000  -0.286659   0.400283   0.000000        A  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Reconstructed Data:\n",
            "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
            "0  0.001222  0.051230 -0.010858  0.011527 -0.038525 -0.010794 -0.017388   \n",
            "1  0.013033 -0.047068 -0.014564 -0.002644 -0.002713 -0.023847 -0.027708   \n",
            "2 -0.019266 -0.047340  0.044468 -0.049252 -0.033394 -0.001851  0.061120   \n",
            "3  0.012673 -0.051851 -0.048284  0.070449  0.059651 -0.038097 -0.069060   \n",
            "4  0.022167  0.034424  0.007942  0.028903  0.088881  0.047242 -0.022464   \n",
            "\n",
            "   feature8  feature9  feature10  ...  feature22  feature23  feature24  \\\n",
            "0 -0.027150 -0.093212   0.003587  ...   0.024312  -0.024564   0.015795   \n",
            "1  0.015451 -0.032056   0.024855  ...   0.028539  -0.026939   0.001119   \n",
            "2  0.000428  0.040306  -0.017797  ...  -0.053198  -0.035439   0.038795   \n",
            "3  0.042647  0.028718   0.038926  ...   0.056768   0.042240  -0.060483   \n",
            "4  0.058807 -0.157021   0.010146  ...   0.033458   0.016075  -0.053883   \n",
            "\n",
            "   feature25  feature26  feature27  feature28  feature29  feature30  subtype  \n",
            "0  -0.022953  -0.018653   0.000933   0.024253  -0.034642   0.006601        B  \n",
            "1  -0.038547   0.004388   0.008338  -0.007127  -0.010654  -0.002142        C  \n",
            "2   0.008641   0.112652   0.028613   0.020412  -0.021400  -0.097453        C  \n",
            "3  -0.004896  -0.061169  -0.008934  -0.031328   0.031571   0.074570        A  \n",
            "4  -0.013048  -0.075221  -0.001367  -0.007970  -0.032233   0.044676        A  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "\n",
        "# larger example dataset with missing values\n",
        "np.random.seed(42)\n",
        "num_samples = 6000\n",
        "num_features = 30\n",
        "data = {\n",
        "    f'feature{i}': np.random.normal(size=num_samples) for i in range(1, num_features + 1)\n",
        "}\n",
        "data['subtype'] = np.random.choice(['A', 'B', 'C'], size=num_samples)\n",
        "\n",
        "# Introduce random missing values\n",
        "missing_mask = np.random.rand(num_samples, num_features) < 0.2\n",
        "for col in data.keys():\n",
        "    if col != 'subtype':\n",
        "        data[col][missing_mask[:, int(col[-1]) - 1]] = np.nan\n",
        "\n",
        "omicMiss = pd.DataFrame(data)\n",
        "\n",
        "# Normalize the dataset\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = [f'feature{i}' for i in range(1, num_features + 1)]\n",
        "omicMiss[numeric_cols] = scaler.fit_transform(omicMiss[numeric_cols])\n",
        "\n",
        "# Handle missing values by filling NaNs with a specific value\n",
        "missing_value_placeholder = 0\n",
        "omicMiss.fillna(missing_value_placeholder, inplace=True)\n",
        "\n",
        "# Pretrain the TabNet model\n",
        "pretrained_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax'\n",
        ")\n",
        "\n",
        "max_epochs = 10\n",
        "pretrained_model.fit(\n",
        "    omicMiss[numeric_cols].values,\n",
        "    max_epochs=max_epochs\n",
        ")\n",
        "\n",
        "# Define the tabnet_recon function\n",
        "\n",
        "def tabnet_recon(omicMiss, network, omicMissMean=0, omicMissSd=1):\n",
        "    omicMissTrain = omicMiss.copy()\n",
        "    omicMissTrain[numeric_cols] = scaler.transform(omicMissTrain[numeric_cols])\n",
        "\n",
        "    # Convert input data to tensors for use in the TabNet network\n",
        "    inputData = torch.tensor(omicMissTrain[numeric_cols].values, dtype=torch.float32)\n",
        "\n",
        "    # Pass the input data through the TabNet network\n",
        "    results = network.predict(inputData)\n",
        "\n",
        "    # Handle potential tuple output\n",
        "    if isinstance(results, tuple):\n",
        "        results = results[0]  # Use the first element of the tuple\n",
        "\n",
        "    # Denormalize the reconstructed data\n",
        "    omicNa_tab = (results * omicMissSd) + omicMissMean\n",
        "\n",
        "    # Combine reconstructed data with original categorical column\n",
        "    omicNa_tab = pd.DataFrame(omicNa_tab, columns=numeric_cols)\n",
        "    omicNa_tab['subtype'] = omicMiss['subtype']\n",
        "\n",
        "    # Patch the reconstructed data into the original data with missing values\n",
        "    omicRec_tab = omicMiss.copy()\n",
        "    omicRec_tab.update(omicNa_tab)\n",
        "\n",
        "    return omicRec_tab\n",
        "\n",
        "\n",
        "# Extract true missing values before filling\n",
        "true_missing_values = omicMiss[numeric_cols].values\n",
        "\n",
        "# Reconstruct missing values using the pretrained model\n",
        "reconstructed_data = tabnet_recon(omicMiss, network=pretrained_model)\n",
        "\n",
        "# Extract imputed values\n",
        "imputed_values = reconstructed_data[numeric_cols].values\n",
        "\n",
        "# Calculate MAE, R-squared, and RMSE\n",
        "mae = np.mean(np.abs(imputed_values - true_missing_values))\n",
        "total_variation = np.sum((true_missing_values - np.mean(true_missing_values)) ** 2)\n",
        "residual_variation = np.sum((true_missing_values - imputed_values) ** 2)\n",
        "r_squared = 1 - (residual_variation / total_variation)\n",
        "rmse = np.sqrt(np.mean((imputed_values - true_missing_values) ** 2))\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R-squared:\", r_squared)\n",
        "print(\"RMSE:\", rmse)\n",
        "\n",
        "# Print original and reconstructed data (only printing a subset)\n",
        "print(\"Original Data:\")\n",
        "print(omicMiss.head())\n",
        "print(\"\\nReconstructed Data:\")\n",
        "print(reconstructed_data.head())\n"
      ]
    }
  ]
}